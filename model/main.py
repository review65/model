# main.py (WEEKLY - COMPARE 3 MODELS + OPTIMIZE 3 MODELS)
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import functools # (Import functools)

# --- !! 1. IMPORT MODELS FOR COMPARISON !! ---
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor

from aggregate_weekly import aggregate_data
from price_optimizer import ParticleSwarmOptimizer # <-- à¹€à¸›à¸´à¸”à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

# --- 3. LOAD WEEKLY DATA ---
DATA_FILE = r'E:\model\model\Amazon Sale Report.csv' # (à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š Path à¸™à¸µà¹‰)
print("\n=== Loading and Aggregating Weekly Data ===")
df = aggregate_data(DATA_FILE)

# --- 4. ENCODE CATEGORICAL FEATURES ---
print("\nEncoding categorical features (SKU, Category, Size)...")
encoders = {}
for col in ['SKU', 'Category', 'Size']:
    le = LabelEncoder()
    # (à¹à¸à¹‰à¸›à¸±à¸à¸«à¸² SKU à¹ƒà¸«à¸¡à¹ˆà¸—à¸µà¹ˆà¸­à¸²à¸ˆà¹€à¸ˆà¸­à¹ƒà¸™ test set)
    df[col] = le.fit_transform(df[col].astype(str)) 
    encoders[col] = le

# --- 5. NEW WEEKLY FEATURE ENGINEERING ---
print("\n=== Creating WEEKLY Features ===")
df = df.sort_values(by=['SKU', 'Date'])
# Lag Features
df['Qty_lag_1'] = df.groupby('SKU')['Total_Qty'].shift(1)
df['Price_lag_1'] = df.groupby('SKU')['Avg_Price'].shift(1)
df['price_change_pct'] = (df['Avg_Price'] - df['Price_lag_1']) / (df['Price_lag_1'] + 1e-6)
# Time Features
df = df.reset_index()
df['week_of_year'] = df['Date'].dt.isocalendar().week.astype(float)
df['month'] = df['Date'].dt.month.astype(float)
df['month_sin'] = np.sin(2 * np.pi * df['month']/12)
df['month_cos'] = np.cos(2 * np.pi * df['month']/12)
print(f"Original shape: {df.shape}")
df = df.dropna()
print(f"Shape after dropping NaNs: {df.shape}")

# --- 6. NEW FEATURE LIST (Weekly) ---
features = [
    'SKU', 'Category', 'Size', 'Avg_Price', 'Max_Price', 'Min_Price',
    'week_of_year', 'month', 'month_sin', 'month_cos',
    'Qty_lag_1',
    'Price_lag_1', 'price_change_pct',
    'Has_Promotion' # (à¸¢à¸·à¸™à¸¢à¸±à¸™à¸§à¹ˆà¸² Transaction_Count à¸­à¸­à¸à¹à¸¥à¹‰à¸§)
]
target = 'Total_Qty'
NUM_FEATURES = len(features)
print(f"\nTotal weekly features: {NUM_FEATURES}")

# --- 7. Time-based Train/Val/Test Split ---
print("\n=== Time-based Data Split ===")
print("Sorting by Date first for proper time-based split...")
df = df.sort_values(by=['Date'])
total_records = len(df)
train_end_idx = int(total_records * 0.7)
val_end_idx = int(total_records * 0.85) 
df_train = df.iloc[:train_end_idx].copy()
df_val = df.iloc[train_end_idx:val_end_idx].copy()
df_test = df.iloc[val_end_idx:].copy()

print(f"Train period: {df_train['Date'].min()} to {df_train['Date'].max()}")
print(f"Val period:   {df_val['Date'].min()} to {df_val['Date'].max()}")
print(f"Test period:  {df_test['Date'].min()} to {df_test['Date'].max()}")

# --- 8. Fit Scaler ---
print("\n=== Fitting Scaler on Train Set ONLY ===")
X_train_raw = df_train[features].values
y_train_target = df_train[target].values
X_test_raw = df_test[features].values
y_test_raw = df_test[target].values

scaler_X = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train_raw)
X_test_scaled = scaler_X.transform(X_test_raw)

print(f"X_train shape (flat): {X_train_scaled.shape}")
print(f"X_test shape (flat): {X_test_scaled.shape}")

# --- 9. Build, Train, and Compare Models ---
print("\n=== Training and Comparing Models ===")
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(
        n_estimators=100,
        min_samples_leaf=10, 
        random_state=42,
        n_jobs=-1
    ),
    "Neural Network (MLP)": MLPRegressor(
        hidden_layer_sizes=(64, 32),
        activation='relu',
        random_state=42,
        max_iter=500,
        early_stopping=True
    )
}

results = {}
best_model_name = None
best_r2 = -np.inf

print(f"\nTest Set Performance (Actual Mean: {y_test_raw.mean():.2f} units)")
print("-" * 50)

for name, model in models.items():
    print(f"Training: {name}...")
    model.fit(X_train_scaled, y_train_target)
    predictions_raw = model.predict(X_test_scaled)
    
    r2 = r2_score(y_test_raw, predictions_raw)
    mae = mean_absolute_error(y_test_raw, predictions_raw)
    rmse = np.sqrt(mean_squared_error(y_test_raw, predictions_raw))
    
    # (à¹€à¸à¹‡à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸—à¸£à¸™à¹à¸¥à¹‰à¸§à¹„à¸§à¹‰)
    results[name] = {'RÂ²': r2, 'MAE': mae, 'RMSE': rmse, 'model_obj': model, 'preds': predictions_raw}
    
    print(f"  RÂ²:   {r2:.4f}")
    print(f"  MAE:  {mae:.2f} units")
    print(f"  RMSE: {rmse:.2f} units")
    print("-" * 50)
    
    if r2 > best_r2:
        best_r2 = r2
        best_model_name = name

print(f"\nðŸ† Best Model: {best_model_name} (Based on RÂ²) ðŸ†")

# --- 10. Visualization (Plotting the BEST model) ---
best_model_preds = results[best_model_name]['preds']
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.scatter(y_test_raw, best_model_preds, alpha=0.5)
plt.plot([y_test_raw.min(), y_test_raw.max()],
         [y_test_raw.min(), y_test_raw.max()], 'r--', lw=2)
plt.xlabel('Actual Demand')
plt.ylabel('Predicted Demand')
plt.title(f'Actual vs Predicted ({best_model_name})\n(RÂ²={results[best_model_name]["RÂ²"]:.4f})')
plt.grid(True)
plt.subplot(1, 2, 2)
residuals = y_test_raw - best_model_preds
plt.hist(residuals, bins=50, edgecolor='black')
plt.xlabel('Residual')
plt.ylabel('Frequency')
plt.title(f'Residual Distribution ({best_model_name})')
plt.grid(True)
plt.tight_layout()
plt.savefig(f'model_evaluation_weekly_COMPARISON.png', dpi=150)
print(f"\nVisualization for best model ({best_model_name}) saved to: model_evaluation_weekly_COMPARISON.png")


# --- !! 11. PRICE OPTIMIZATION SETUP (FIXED) !! ---
print("\n" + "="*50)
print("=== Price Optimization (ACTIVATED) ===")
print("="*50)

# 1. à¸„à¹‰à¸™à¸«à¸² SKUs à¸—à¸µà¹ˆà¹€à¸£à¸²à¸•à¹‰à¸­à¸‡à¸à¸²à¸£
# (à¹€à¸¥à¸·à¸­à¸ Top 3 SKUs à¸—à¸µà¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸¢à¸­à¸°à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸ˆà¸²à¸ Train Set)
# (à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰à¸–à¸¹à¸à¹€à¸‚à¹‰à¸²à¸£à¸«à¸±à¸ª (Encoded) à¹à¸¥à¹‰à¸§à¹‚à¸”à¸¢ LabelEncoder)
top_skus_in_train = df_train['SKU'].value_counts().head(3).index.values

target_skus_encoded = top_skus_in_train

print(f"Optimizing for Top 3 Encoded SKUs from Train Set: {target_skus_encoded}")

PRODUCT_COSTS = np.array([300, 400, 600]) # (à¸›à¸£à¸±à¸šà¸•à¹‰à¸™à¸—à¸¸à¸™à¸•à¸²à¸¡à¸ˆà¸£à¸´à¸‡)
NUM_PRODUCTS = len(target_skus_encoded)

# 2. à¸”à¸¶à¸‡ "à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸™" (à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸¥à¹ˆà¸²à¸ªà¸¸à¸”)
# (à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ "à¸”à¸´à¸š" (unscaled) à¸ˆà¸²à¸à¹à¸–à¸§à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸‚à¸­à¸‡ Test Set à¹€à¸›à¹‡à¸™à¸à¸²à¸™)
base_features_unscaled = df_test[features].iloc[-1].values
f_map = {name: idx for idx, name in enumerate(features)} # (Map à¸Šà¸·à¹ˆà¸­ feature à¹„à¸›à¸¢à¸±à¸‡ index)

# 3. Price Bounds
price_bounds = [
    (400, 800),
    (500, 1000),
    (700, 1500)
]

# 4. à¸ªà¸£à¹‰à¸²à¸‡ Objective Function (à¸—à¸µà¹ˆà¸£à¸±à¸š model à¹€à¸›à¹‡à¸™ argument)
def profit_objective_function(prices, model_to_use):
    """
    à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸„à¸³à¸™à¸§à¸“à¸à¸³à¹„à¸£ (à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥ Flat/Weekly)
    """
    model_inputs = []
    
    for i, new_price in enumerate(prices):
        future_features_unscaled = base_features_unscaled.copy()
        today_price = future_features_unscaled[f_map['Avg_Price']]
        
        future_features_unscaled[f_map['SKU']] = target_skus_encoded[i]
        future_features_unscaled[f_map['Avg_Price']] = new_price
        future_features_unscaled[f_map['Max_Price']] = new_price
        future_features_unscaled[f_map['Min_Price']] = new_price
        future_features_unscaled[f_map['Price_lag_1']] = today_price
        future_features_unscaled[f_map['price_change_pct']] = (new_price - today_price) / (today_price + 1e-6)
        future_features_unscaled[f_map['Has_Promotion']] = 0 
        
        model_inputs.append(future_features_unscaled)

    model_inputs_scaled = scaler_X.transform(np.array(model_inputs))
    
    predictions_raw = model_to_use.predict(model_inputs_scaled)
    predictions_raw = np.maximum(0, predictions_raw)
    
    total_profit = np.sum((prices - PRODUCT_COSTS) * predictions_raw)
    return -total_profit  # à¸•à¸´à¸”à¸¥à¸šà¹€à¸žà¸£à¸²à¸° PSO minimize

# --- !! 12. RUN OPTIMIZER FOR ALL 3 MODELS !! ---

for model_name, data in results.items():
    
    print(f"\n--- Optimizing Prices using: {model_name} (RÂ²: {data['RÂ²']:.4f}) ---")
    
    current_model = data['model_obj']
    
    # (à¸ªà¸£à¹‰à¸²à¸‡ lambda function à¹€à¸žà¸·à¹ˆà¸­à¸ªà¹ˆà¸‡ model à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹€à¸‚à¹‰à¸²à¹„à¸›)
    objective_wrapper = functools.partial(profit_objective_function, model_to_use=current_model)
    
    optimizer = ParticleSwarmOptimizer(
        objective_function=objective_wrapper,
        bounds=price_bounds,
        num_particles=50,
        max_iter=100
    )

    optimal_prices, max_profit = optimizer.optimize()

    print(f"\n{'='*50}")
    print(f"OPTIMIZATION RESULTS (For {model_name}):")
    print(f"{'='*50}")
    print(f"  Optimal Prices: {np.round(optimal_prices, 2)}")
    print(f"  Maximum Profit: à¸¿{-max_profit:,.2f}")
    print(f"{'='*50}")

    # (à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œà¸¢à¹ˆà¸­à¸¢à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸™à¸µà¹‰)
    print(f"  Predicted Demands at these prices:")
    final_inputs_unscaled = []
    for i, price in enumerate(optimal_prices):
        future_features_unscaled = base_features_unscaled.copy()
        today_price = future_features_unscaled[f_map['Avg_Price']]
        future_features_unscaled[f_map['SKU']] = target_skus_encoded[i]
        future_features_unscaled[f_map['Avg_Price']] = price
        future_features_unscaled[f_map['Max_Price']] = price
        future_features_unscaled[f_map['Min_Price']] = price
        future_features_unscaled[f_map['Price_lag_1']] = today_price
        future_features_unscaled[f_map['price_change_pct']] = (price - today_price) / (today_price + 1e-6)
        future_features_unscaled[f_map['Has_Promotion']] = 0
        final_inputs_unscaled.append(future_features_unscaled)

    final_inputs_scaled = scaler_X.transform(np.array(final_inputs_unscaled))
    test_demands = current_model.predict(final_inputs_scaled)
    test_demands = np.maximum(0, test_demands)

    for i in range(NUM_PRODUCTS):
        print(f"    SKU (Enc) {target_skus_encoded[i]}: {test_demands[i]:.2f} units @ à¸¿{optimal_prices[i]:.2f}")
        print(f"      -> Profit: à¸¿{(optimal_prices[i] - PRODUCT_COSTS[i]) * test_demands[i]:,.2f}")